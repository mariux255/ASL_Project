{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "from preprocessing import exctract_json_data, define_categories\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import tqdm\n",
    "data_directory = \"/Users/mjo/Desktop/WLASL/Processed_data/100\"\n",
    "\n",
    "\n",
    "count_dictionary, video_id_dictionary = exctract_json_data()\n",
    "labels_100, _, _, _, _ = define_categories(count_dictionary)\n",
    "\n",
    "labels_iterated = {}\n",
    "counter = 0\n",
    "for label in labels_100:\n",
    "    labels_iterated[label] = counter\n",
    "    counter += 1\n",
    "\n",
    "inv_video_id_dictionary = {}\n",
    "for k, v in video_id_dictionary.items(): \n",
    "    for video in v:\n",
    "        inv_video_id_dictionary[video] = k\n",
    "        \n",
    "def make_training_data(labels_x, video_id_dictionary, labels_iterated):\n",
    "    training_data = []\n",
    "    num_labels = len(labels_x)\n",
    "    for label in (labels_x):\n",
    "        for video in video_id_dictionary[label]:\n",
    "            path = os.path.join(data_directory, video)\n",
    "            for file in (os.listdir(path)):\n",
    "                if \"jpg\" in file:\n",
    "                    try:\n",
    "                        path = os.path.join(data_directory,video, file)\n",
    "                        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "                        training_data.append([np.array(img),labels_iterated[label]])\n",
    "                    except Exception as e:\n",
    "                        print(e)\n",
    "                        pass\n",
    "    return training_data\n",
    "\n",
    "training_data = make_training_data(labels_100, video_id_dictionary, labels_iterated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126956\n"
     ]
    }
   ],
   "source": [
    "#import torch\n",
    "#trainloader = torch.utils.data.DataLoader(training_data, batch_size=20,\n",
    "#                                          shuffle=True, num_workers=2)\n",
    "X = [None] * len(training_data)\n",
    "y = [None] * len(X)\n",
    "counter = 0\n",
    "for i in training_data:\n",
    "    X[counter] = torch.Tensor(i[0])\n",
    "    y[counter] = i[1]\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_inputs = torch.stack(X)\n",
    "training_labels = (np.array(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_labels = torch.LongTensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 128, 5)\n",
    "        self.pool = nn.MaxPool2d(4, 4)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(128, 256, 5)\n",
    "        self.conv3 = nn.Conv2d(256, 512, 5)\n",
    "        self.conv4 = nn.Conv2d(512, 256, 5)\n",
    "        self.fc3 = nn.Linear(16384, 100)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = self.pool2(F.relu(self.conv3(x)))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = x.view(-1, 16384)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(ys, ts):\n",
    "    print(\"ts:\", ts.shape)\n",
    "    print(\"ys:\", ys.shape)\n",
    "    y = torch.argmax(ys, dim = 1)\n",
    "    x = torch.argmax(ts, dim = 1)\n",
    "    correct = 0\n",
    "    for i in range(len(y)):\n",
    "        if y[i] == x[i]:\n",
    "            correct += 1\n",
    "    return correct/len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Loss: 8.099489212036133\n",
      "Epoch: 0. Loss: 2211.567138671875\n",
      "Epoch: 0. Loss: 75.22601318359375\n",
      "Epoch: 0. Loss: 126.21714782714844\n",
      "Epoch: 0. Loss: 7.4318695068359375\n",
      "Epoch: 0. Loss: 8.70337200164795\n",
      "Epoch: 0. Loss: 7.1411895751953125\n",
      "Epoch: 0. Loss: 4.5265116691589355\n",
      "Epoch: 0. Loss: 4.67000150680542\n",
      "Epoch: 0. Loss: 4.687300682067871\n",
      "Epoch: 0. Loss: 4.63635778427124\n",
      "Epoch: 0. Loss: 4.613581657409668\n",
      "Epoch: 0. Loss: 4.5384063720703125\n",
      "Epoch: 0. Loss: 8.408697128295898\n",
      "Epoch: 0. Loss: 4.632040977478027\n",
      "Epoch: 0. Loss: 4.605716705322266\n",
      "Epoch: 0. Loss: 4.605222702026367\n",
      "Epoch: 0. Loss: 4.602627754211426\n",
      "Epoch: 0. Loss: 4.60354471206665\n",
      "Epoch: 0. Loss: 4.603082180023193\n",
      "Epoch: 0. Loss: 4.5861496925354\n",
      "Epoch: 0. Loss: 4.486729145050049\n",
      "Epoch: 0. Loss: 5.516018867492676\n",
      "Epoch: 0. Loss: 4.624083518981934\n",
      "Epoch: 0. Loss: 4.603348731994629\n",
      "Epoch: 0. Loss: 4.604841232299805\n",
      "Epoch: 0. Loss: 4.605774879455566\n",
      "Epoch: 0. Loss: 4.604333877563477\n",
      "Epoch: 0. Loss: 4.60261344909668\n",
      "Epoch: 0. Loss: 4.604592800140381\n",
      "Epoch: 0. Loss: 4.606985569000244\n",
      "Epoch: 0. Loss: 4.6937761306762695\n",
      "Epoch: 0. Loss: 4.608290672302246\n",
      "Epoch: 0. Loss: 4.602814674377441\n",
      "Epoch: 0. Loss: 4.60286808013916\n",
      "Epoch: 0. Loss: 4.60773229598999\n",
      "Epoch: 0. Loss: 4.6038947105407715\n",
      "Epoch: 0. Loss: 4.603764533996582\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-7ffbb013deb6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 100\n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i in range(0,len(training_inputs), BATCH_SIZE):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs = training_inputs[i:i+BATCH_SIZE].view(-1, 1, 256, 256)\n",
    "        labels = training_labels[i:i+BATCH_SIZE]\n",
    "        #inputs, labels = batch\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        inputs = inputs.view(-1,1,256,256)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward + backward + optimize\n",
    "        \n",
    "        outputs = net(inputs)\n",
    "        value, index = (torch.max(outputs,0))\n",
    "        value, index = (torch.max(labels,0))\n",
    "        #print(accuracy(outputs,labels))\n",
    "        preds = torch.max(outputs, 1)[1]\n",
    "        loss = criterion(outputs, torch.LongTensor(labels))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f\"Epoch: {epoch}. Loss: {loss}\")\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
